{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_source_csv(folder_path):\n",
    "    adhd_df = pd.read_csv(folder_path + '/adhd.csv')\n",
    "    aspergers_df = pd.read_csv(folder_path + '/aspergers.csv')\n",
    "    depression_df = pd.read_csv(folder_path + '/depression.csv')\n",
    "    ocd_df = pd.read_csv(folder_path + '/ocd.csv')\n",
    "    ptsd_df = pd.read_csv(folder_path + '/ptsd.csv')\n",
    "\n",
    "    # join everything together with a new column for the label\n",
    "    adhd_df['subreddit'] = 'adhd'\n",
    "    aspergers_df['subreddit'] = 'aspergers'\n",
    "    depression_df['subreddit'] = 'depression'\n",
    "    ocd_df['subreddit'] = 'ocd'\n",
    "    ptsd_df['subreddit'] = 'ptsd'\n",
    "\n",
    "    return pd.concat([adhd_df, aspergers_df, depression_df, ocd_df, ptsd_df])\n",
    "\n",
    "def read_clean_csv(file_path):\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87078\n",
      "50750\n"
     ]
    }
   ],
   "source": [
    "dd = pd.read_csv('Dataset/dataset.csv')\n",
    "# Display number of rows \n",
    "print(dd.shape[0])\n",
    "#display number of different authors\n",
    "print(dd['author'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87078\n"
     ]
    }
   ],
   "source": [
    "df = read_clean_csv('Dataset/dataset.csv')\n",
    "\n",
    "# Print the number of rows of the dataset\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['author', 'body', 'creation_date', 'id', 'num_comments', 'score',\n",
      "       'subreddit', 'title', 'upvote_ratio', 'url', 'SubReddit'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=['SubReddit'])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                author                                               body  \\\n",
      "0  HotConversation1273  A few months ago I was accepted into this full...   \n",
      "1           snorefestt  Hey guys, I was curious if anyone else has the...   \n",
      "2               etyf12   \\n\\ni have 6 exams in the next 2 weeks one of...   \n",
      "3    GetHairOrDieTryin  Is there anyone out there that is struggling w...   \n",
      "4         ZeroTransPat  Whenever I get hungry, I never eat because I d...   \n",
      "\n",
      "  creation_date      id  num_comments  score subreddit  \\\n",
      "0    2021-12-22  rmbjwb             1      1      ADHD   \n",
      "1    2021-12-22  rmbd1y             3      5      ADHD   \n",
      "2    2021-12-22  rmbbvu             1      2      ADHD   \n",
      "3    2021-12-22  rmba1t             3      2      ADHD   \n",
      "4    2021-12-22  rmb8lm             2      1      ADHD   \n",
      "\n",
      "                                               title  upvote_ratio  \\\n",
      "0    I get extremely anxious if Iâ€™m not working 24/7           1.0   \n",
      "1  I can't will myself to clean my own house, but...           1.0   \n",
      "2                                   i need some help           1.0   \n",
      "3                              Anyone up for a chat?           1.0   \n",
      "4                     Figuring out what to eat sucks           1.0   \n",
      "\n",
      "                                                 url SubReddit  \n",
      "0  https://www.reddit.com/r/ADHD/comments/rmbjwb/...      adhd  \n",
      "1  https://www.reddit.com/r/ADHD/comments/rmbd1y/...      adhd  \n",
      "2  https://www.reddit.com/r/ADHD/comments/rmbbvu/...      adhd  \n",
      "3  https://www.reddit.com/r/ADHD/comments/rmba1t/...      adhd  \n",
      "4  https://www.reddit.com/r/ADHD/comments/rmb8lm/...      adhd  \n"
     ]
    }
   ],
   "source": [
    "# Drop NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Drop removed bodies\n",
    "df = df[df['body'] != '[removed]']\n",
    "df = df[df['body'] != '[deleted]']\n",
    "\n",
    "#change column name 'created_utc' to 'creation_date'\n",
    "df.rename(columns={'created_utc': 'creation_date'}, inplace=True)\n",
    "#change the date format to contain only the date, knowing that the date is in the format 2021-12-22T18:32:56.000Z\n",
    "df['creation_date'] = df['creation_date'].str.split('T').str[0]\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87078\n"
     ]
    }
   ],
   "source": [
    "print(df.shape[0])\n",
    "# Create a new .csv file with the cleaned data 'df' named dataset.csv, in the folder 'Dataset'\n",
    "df.to_csv('Dataset/dataset.csv', index=False)\n",
    "\n",
    "# Create a new json file with the cleaned data 'df' named dataset, in the folder 'Dataset'\n",
    "df.to_json('Dataset/dataset.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most used words in the body column\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Get the most used words in the body column\n",
    "def get_most_used_words(df, n):\n",
    "    # Get all the words in the body column\n",
    "    all_words = ' '.join(df['body']).split()\n",
    "    # Count the number of times each word appears\n",
    "    word_counts = Counter(all_words)\n",
    "    # Get the n most common words\n",
    "    return word_counts.most_common(n)\n",
    "\n",
    "# Get the 10 most used words in the body column and their counts\n",
    "most_used_words = get_most_used_words(dd, 10)\n",
    "print(most_used_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most used words in the body column that are not stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Get the most used words in the body column that are not stop words\n",
    "def get_most_used_words_without_stop_words(df, n):\n",
    "    # Get all the words in the body column\n",
    "    all_words = ' '.join(df['body']).split()\n",
    "    # Get the stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Count the number of times each word appears\n",
    "    word_counts = Counter(all_words)\n",
    "    # Get the n most common words that are not stop words\n",
    "    return [(word, count) for word, count in word_counts.most_common() if word not in stop_words][:n]\n",
    "\n",
    "# Get the 10 most used words in the body column that are not stop words and their counts\n",
    "most_used_words_without_stop_words = get_most_used_words_without_stop_words(dd, 10)\n",
    "print(most_used_words_without_stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the month/year combos with the most posts\n",
    "import calendar\n",
    "\n",
    "# Get the months with the most posts\n",
    "def get_months_with_most_posts(df):\n",
    "    # Get the month of each post\n",
    "    months = df['creation_date'].str.split('-').str[1]\n",
    "    # Count the number of posts for each month\n",
    "    month_counts = Counter(months)\n",
    "    # Get the months with the most posts\n",
    "    return [calendar.month_name[int(month)] for month, _ in month_counts.most_common()]\n",
    "\n",
    "# Get the months with the most posts\n",
    "months_with_most_posts = get_months_with_most_posts(dd)\n",
    "print(months_with_most_posts)\n",
    "\n",
    "# plot it\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the number of posts for each month\n",
    "months = dd['creation_date'].str.split('-').str[1]\n",
    "month_counts = Counter(months)\n",
    "# Get the months\n",
    "months = [calendar.month_name[int(month)] for month, _ in month_counts.items()]\n",
    "months.reverse()\n",
    "# Get the number of posts\n",
    "counts = list(month_counts.values())\n",
    "counts.reverse()\n",
    "# Plot the number of posts for each month in month calendar order\n",
    "plt.bar(months, counts)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Posts')\n",
    "plt.title('Number of Posts per Month')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the years in order of most posts\n",
    "def get_years_in_order_of_most_posts(df):\n",
    "    # Get the year of each post\n",
    "    years = df['creation_date'].str.split('-').str[0]\n",
    "    # Count the number of posts for each year\n",
    "    year_counts = Counter(years)\n",
    "    # Get the years in order of most posts\n",
    "    return [year for year, _ in year_counts.most_common()]\n",
    "\n",
    "# Get the years in order of most posts\n",
    "years_in_order_of_most_posts = get_years_in_order_of_most_posts(dd)\n",
    "print(years_in_order_of_most_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the max, min, mode, and mean of the number of comments\n",
    "max_comments = dd['num_comments'].max()\n",
    "min_comments = dd['num_comments'].min()\n",
    "mode_comments = dd['num_comments'].mode()\n",
    "mean_comments = dd['num_comments'].mean()\n",
    "print(max_comments, min_comments, mode_comments, mean_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some stats about the upvote ratio\n",
    "\n",
    "min_ratio = dd['upvote_ratio'].min()\n",
    "mean_ratio = dd['upvote_ratio'].mean()\n",
    "\n",
    "print(min_ratio, mean_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values per column\n",
    "unique_counts = dd.nunique()\n",
    "\n",
    "# Missing values per column\n",
    "missing_values = dd.isnull().sum()\n",
    "\n",
    "# Value counts for categorical columns\n",
    "author_counts = dd['author'].value_counts()\n",
    "subreddit_counts = dd['subreddit'].value_counts()\n",
    "subreddit_counts = dd['SubReddit'].value_counts()\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nNumber of Unique Values per Column:\\n\", unique_counts)\n",
    "print(\"\\nMissing Values per Column:\\n\", missing_values)\n",
    "print(\"\\nAuthor Counts:\\n\", author_counts)\n",
    "print(\"\\nSubreddit Counts:\\n\", subreddit_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_stats_per_subreddit(df):\n",
    "    # Get the mean number of comments, upvote ratio, and score for each subreddit\n",
    "    return df.groupby('SubReddit')[['num_comments', 'upvote_ratio', 'score']].mean()\n",
    "\n",
    "# Get the mean number of comments, upvote ratio, and score for each subreddit\n",
    "mean_stats_per_subreddit = get_mean_stats_per_subreddit(dd)\n",
    "print(mean_stats_per_subreddit)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
